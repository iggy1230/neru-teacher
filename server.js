import textToSpeech from '@google-cloud/text-to-speech';
import { GoogleGenerativeAI } from "@google/generative-ai";
import express from 'express';
import cors from 'cors';
import path from 'path';
import { fileURLToPath } from 'url';
import WebSocket, { WebSocketServer } from 'ws';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const app = express();

app.use(cors());
app.use(express.json({ limit: '50mb' }));
app.use(express.static(path.join(__dirname, '.')));

// APIåˆæœŸåŒ–
let genAI, ttsClient;
try {
    genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
    ttsClient = new textToSpeech.TextToSpeechClient({ 
        credentials: JSON.parse(process.env.GOOGLE_CREDENTIALS_JSON) 
    });
} catch (e) { console.error("Init Error:", e.message); }

// --- é€šå¸¸ã®TTS (éŸ³å£°åˆæˆ) ---
function createSSML(text, mood) {
    let rate = "1.0", pitch = "0.0";
    if (mood === "happy") { rate = "1.1"; pitch = "+2st"; }
    // è¨˜å·å‰Šé™¤
    let clean = text.replace(/[\u{1F600}-\u{1F6FF}]/gu, '').replace(/ğŸ¾|âœ¨|â­|ğŸµ|ğŸŸ|ğŸ¤/g, '');
    // çŸ­ã„æ–‡ã¯ã‚¿ã‚°ãªã—ã§å®‰å®šåŒ–
    if (clean.length < 5 || clean.includes("ã©ã®æ•™ç§‘")) return `<speak>${clean}</speak>`;
    
    clean = clean.replace(/&/g, 'ã¨').replace(/[<>]/g, ' ');
    return `<speak><prosody rate="${rate}" pitch="${pitch}">${clean.replace(/â€¦â€¦/g, '<break time="500ms"/>').replace(/ã«ã‚ƒ/g, '<prosody pitch="+2st">ã«ã‚ƒ</prosody>')}</prosody></speak>`;
}

app.post('/synthesize', async (req, res) => {
    try {
        if (!ttsClient) throw new Error("TTS not ready");
        const { text, mood } = req.body;
        if (!text) return res.status(400).json({ error: "No text" });
        try {
            const [r] = await ttsClient.synthesizeSpeech({
                input: { ssml: createSSML(text, mood) },
                voice: { languageCode: 'ja-JP', name: 'ja-JP-Neural2-B' },
                audioConfig: { audioEncoding: 'MP3' }
            });
            res.json({ audioContent: r.audioContent.toString('base64') });
        } catch (e) {
            // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å¹³æ–‡ã§å†è©¦è¡Œ
            const [r2] = await ttsClient.synthesizeSpeech({
                input: { text: text.replace(/[^a-zA-Z0-9\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]/g, '') },
                voice: { languageCode: 'ja-JP', name: 'ja-JP-Neural2-B' },
                audioConfig: { audioEncoding: 'MP3' }
            });
            res.json({ audioContent: r2.audioContent.toString('base64') });
        }
    } catch (err) { res.status(500).send(err.message); }
});

// --- é€šå¸¸ã®ç”»åƒåˆ†æ ---
app.post('/analyze', async (req, res) => {
    try {
        if (!genAI) throw new Error("GenAI not ready");
        const { image, mode, grade, subject } = req.body;
        const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash", generationConfig: { responseMimeType: "application/json" } });
        const hint = `- "hints": ãƒ’ãƒ³ãƒˆ3ã¤(1.è€ƒãˆæ–¹ 2.å¼ 3.ã»ã¼ç­”ãˆ)ã€‚èªå°¾ã¯ã€Œã€œã«ã‚ƒã€ã€‚`;
        let prompt = mode === 'explain' 
            ? `ãƒãƒ«å…ˆç”Ÿã€‚å°å­¦${grade}${subject}ã€‚1."question":æ›¸ãèµ·ã“ã— 2."correct_answer":æ­£è§£ 3.${hint} 4.è¨˜å·ã¯Ã—Ã·ã€‚JSONé…åˆ—ã€‚`
            : `æ¡ç‚¹ã€‚å°å­¦${grade}${subject}ã€‚1."question":æ›¸ãèµ·ã“ã— 2."correct_answer":æ­£è§£ 3."student_answer":æ‰‹æ›¸ãèª­å–(ç©ºæ¬„ãªã‚‰"") 4.${hint} JSONé…åˆ—ã€‚`;
        const result = await model.generateContent([{ inlineData: { mime_type: "image/jpeg", data: image } }, { text: prompt }]);
        res.json(JSON.parse(result.response.text().replace(/\*/g, 'Ã—').replace(/\//g, 'Ã·')));
    } catch (err) { res.status(500).json({ error: "AI Error" }); }
});

app.get('*', (req, res) => res.sendFile(path.join(__dirname, 'index.html')));
const PORT = process.env.PORT || 3000;
const server = app.listen(PORT, () => console.log(`Server running on port ${PORT}`));

// --- â˜…Live API Proxy (ã“ã“ãŒé‡è¦) ---
const wss = new WebSocketServer({ server });

wss.on('connection', (clientWs) => {
    console.log('Client connected to Live Chat');
    let geminiWs = null;
    const GEMINI_URL = `wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidirectionalGenerateContent?key=${process.env.GEMINI_API_KEY}`;

    try {
        geminiWs = new WebSocket(GEMINI_URL);

        geminiWs.on('open', () => {
            console.log('Connected to Gemini');
            const setupMsg = {
                setup: {
                    model: "models/gemini-2.0-flash-exp",
                    generation_config: {
                        response_modalities: ["AUDIO"],
                        speech_config: { voice_config: { prebuilt_voice_config: { voice_name: "Puck" } } }
                    },
                    system_instruction: {
                        parts: [{ text: `ã‚ãªãŸã¯å°å­¦æ ¡ã®ãƒãƒ«å…ˆç”Ÿã§ã™ã€‚èªå°¾ã¯ã€Œã«ã‚ƒã€ã€‚çŸ­ãã€æ˜ã‚‹ãã€å­ä¾›ã¨ä¼šè©±ã—ã¦ã€‚` }]
                    }
                }
            };
            geminiWs.send(JSON.stringify(setupMsg));
        });

        geminiWs.on('message', (data) => {
            if (clientWs.readyState === WebSocket.OPEN) clientWs.send(data);
        });

        geminiWs.on('error', (e) => console.error('Gemini WS Error:', e));
        geminiWs.on('close', () => console.log('Gemini WS Closed'));

    } catch (e) { console.error("Connection failed:", e); clientWs.close(); }

    clientWs.on('message', (data) => {
        try {
            const parsed = JSON.parse(data);
            if (parsed.realtime_input && geminiWs && geminiWs.readyState === WebSocket.OPEN) {
                // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰æ¥ãŸãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾Geminiã¸è»¢é€
                geminiWs.send(JSON.stringify(parsed));
            }
        } catch (e) { console.error("Msg Error:", e); }
    });

    clientWs.on('close', () => {
        if (geminiWs && geminiWs.readyState === WebSocket.OPEN) geminiWs.close();
    });
});